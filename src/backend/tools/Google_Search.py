import os
import logging
import asyncio
import time
import hashlib
from typing import Tuple, List, Any, Optional, Dict
from dataclasses import dataclass
from functools import lru_cache
from datetime import datetime, timedelta
import json

from langchain.agents import initialize_agent, Tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import TavilySearchResults
from dotenv import load_dotenv

load_dotenv()

# Cáº¥u hÃ¬nh logging vá»›i format tÃ¹y chá»‰nh
logging.basicConfig(
    level=logging.INFO, 
    format='[Google_Search] %(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class SearchConfig:
    """Cáº¥u hÃ¬nh cho Google Search tool"""
    max_results: int = 2
    include_answer: bool = True
    include_raw_content: bool = True
    temperature: float = 0.0
    model: str = "gemini-1.5-flash"
    cache_ttl_hours: int = 24
    rate_limit_per_minute: int = 30
    max_content_length: int = 8000
    timeout_seconds: int = 30
    enable_llm: bool = False

class RateLimiter:
    """Simple rate limiter Ä‘á»ƒ trÃ¡nh spam API"""
    
    def __init__(self, max_calls_per_minute: int = 30):
        self.max_calls = max_calls_per_minute
        self.calls = []
    
    def can_make_call(self) -> bool:
        """Kiá»ƒm tra xem cÃ³ thá»ƒ gá»i API khÃ´ng"""
        now = datetime.now()
        # Loáº¡i bá» cÃ¡c calls cÅ© hÆ¡n 1 phÃºt
        self.calls = [call_time for call_time in self.calls 
                     if now - call_time < timedelta(minutes=1)]
        
        if len(self.calls) < self.max_calls:
            self.calls.append(now)
            return True
        return False
    
    def wait_time(self) -> float:
        """TÃ­nh thá»i gian cáº§n Ä‘á»£i (seconds)"""
        if not self.calls:
            return 0.0
        oldest_call = min(self.calls)
        wait_until = oldest_call + timedelta(minutes=1)
        wait_seconds = (wait_until - datetime.now()).total_seconds()
        return max(0.0, wait_seconds)

class SearchCache:
    """Cache system cho search results"""
    
    def __init__(self, ttl_hours: int = 24):
        self.cache: Dict[str, Dict] = {}
        self.ttl_hours = ttl_hours
    
    def _get_cache_key(self, query: str) -> str:
        """Táº¡o cache key tá»« query"""
        return hashlib.md5(query.lower().strip().encode()).hexdigest()
    
    def get(self, query: str) -> Optional[Tuple[Any, List[str]]]:
        """Láº¥y káº¿t quáº£ tá»« cache"""
        key = self._get_cache_key(query)
        if key not in self.cache:
            return None
        
        entry = self.cache[key]
        # Kiá»ƒm tra TTL
        cache_time = datetime.fromisoformat(entry['timestamp'])
        if datetime.now() - cache_time > timedelta(hours=self.ttl_hours):
            del self.cache[key]
            return None
        
        logger.info(f"ğŸ¯ Cache hit cho query: {query[:50]}...")
        return entry['result'], entry['sources']
    
    def set(self, query: str, result: Any, sources: List[str]):
        """LÆ°u káº¿t quáº£ vÃ o cache"""
        key = self._get_cache_key(query)
        self.cache[key] = {
            'result': result,
            'sources': sources,
            'timestamp': datetime.now().isoformat()
        }
        logger.info(f"ğŸ’¾ Cached result cho query: {query[:50]}...")
    
    def clear_expired(self):
        """XÃ³a cÃ¡c entry Ä‘Ã£ háº¿t háº¡n"""
        now = datetime.now()
        expired_keys = []
        
        for key, entry in self.cache.items():
            cache_time = datetime.fromisoformat(entry['timestamp'])
            if now - cache_time > timedelta(hours=self.ttl_hours):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            logger.info(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a {len(expired_keys)} cache entries háº¿t háº¡n")

class OptimizedGoogleSearch:
    """
    Google Search tool Ä‘Æ°á»£c tá»‘i Æ°u vá»›i caching, rate limiting vÃ  error handling nÃ¢ng cao
    """
    
    def __init__(self, config: SearchConfig = SearchConfig()):
        self.config = config
        self.cache = SearchCache(config.cache_ttl_hours)
        self.rate_limiter = RateLimiter(config.rate_limit_per_minute)
        
        # Khá»Ÿi táº¡o API keys
        self.google_api_key = os.getenv('API_KEY_LLM_SEARCH_TOOL')
        self.tavily_api_key = os.getenv('TAVILY_API_KEY')
        
        # Validate API keys
        self._validate_api_keys()
        
        # Khá»Ÿi táº¡o components
        self.llm = None
        self.tavily_search = None
        self._initialize_components()
    
    def _validate_api_keys(self):
        """Validate API keys"""
        if not self.google_api_key:
            logger.error("âŒ GOOGLE_API_KEY khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y trong biáº¿n mÃ´i trÆ°á»ng")
            raise ValueError("Missing Google API key")
        
        if not self.tavily_api_key:
            logger.error("âŒ TAVILY_API_KEY khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y trong biáº¿n mÃ´i trÆ°á»ng")
            raise ValueError("Missing Tavily API key")
        
        # Set environment variables
        os.environ["GEMINI_API_KEY"] = self.google_api_key
        os.environ["TAVILY_API_KEY"] = self.tavily_api_key
        
        logger.info("âœ… API keys validated successfully")
    
    def _initialize_components(self):
        """Khá»Ÿi táº¡o LLM vÃ  search components"""
        try:
            self.llm = ChatGoogleGenerativeAI(
                model=self.config.model,
                temperature=self.config.temperature,
                google_api_key=self.google_api_key,
                timeout=self.config.timeout_seconds
            )
            
            self.tavily_search = TavilySearchResults(
                max_results=self.config.max_results,
                include_answer=self.config.include_answer,
                include_raw_content=self.config.include_raw_content
            )
            
            logger.info("âœ… Search components initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khá»Ÿi táº¡o components: {str(e)}")
            raise
    
    def _validate_query(self, query: str) -> str:
        """Validate vÃ  clean query"""
        if not query or not query.strip():
            raise ValueError("Query khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng")
        
        query = query.strip()
        if len(query) > 500:
            logger.warning(f"âš ï¸ Query quÃ¡ dÃ i ({len(query)} chars), sáº½ truncate")
            query = query[:500] + "..."
        
        return query
    
    def _process_tavily_results(self, results: Any) -> Tuple[List[str], str]:
        """Xá»­ lÃ½ káº¿t quáº£ tá»« Tavily vá»›i validation"""
        urls = []
        contents = []
        
        try:
            if isinstance(results, list):
                for item in results:
                    if isinstance(item, dict) and "url" in item:
                        urls.append(item["url"])
                        title = item.get('title', 'No title')
                        content = item.get('content', 'No content')
                        
                        # Truncate content náº¿u quÃ¡ dÃ i
                        if len(content) > self.config.max_content_length:
                            content = content[:self.config.max_content_length] + "..."
                        
                        contents.append(f"- **{title}** ({item['url']})\n{content}\n")
                        
            elif isinstance(results, dict) and "url" in results:
                urls.append(results["url"])
                title = results.get('title', 'No title')
                content = results.get('content', 'No content')
                
                if len(content) > self.config.max_content_length:
                    content = content[:self.config.max_content_length] + "..."
                
                contents.append(f"- **{title}** ({results['url']})\n{content}\n")
            
            return urls, "\n".join(contents)
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i xá»­ lÃ½ Tavily results: {str(e)}")
            return [], ""
    
    def _create_optimized_prompt(self, query: str, content: str) -> str:
        """Táº¡o prompt Ä‘Æ°á»£c tá»‘i Æ°u cho LLM"""
        return f"""Báº¡n lÃ  chuyÃªn gia cÆ¡ sá»Ÿ dá»¯ liá»‡u. HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn káº¿t quáº£ tÃ¬m kiáº¿m.

**NGUYÃŠN Táº®C QUAN TRá»ŒNG:**
âœ… **Báº®T BUá»˜C:** Cuá»‘i cÃ¢u tráº£ lá»i PHáº¢I cÃ³ pháº§n "## Nguá»“n tham kháº£o" vá»›i táº¥t cáº£ URL Ä‘Æ°á»£c tÃ¬m tháº¥y
âœ… **Äá»ŠNH Dáº NG:** Sá»­ dá»¥ng Markdown chuáº©n (##, ###, **, -, ```sql)  
âœ… **Ná»˜I DUNG:** Tráº£ lá»i chÃ­nh xÃ¡c, ngáº¯n gá»n, dá»… hiá»ƒu vá» cÆ¡ sá»Ÿ dá»¯ liá»‡u
âœ… **NGÃ”N NGá»®:** Tiáº¿ng Viá»‡t, giá»¯ nguyÃªn thuáº­t ngá»¯ chuyÃªn ngÃ nh

**VÃ Dá»¤ Äá»ŠNH Dáº NG:**
CÃ¢u tráº£ lá»i chÃ­nh vá» chá»§ Ä‘á»...

## CÃ¡c loáº¡i CSDL phá»• biáº¿n
- **PostgreSQL**: MÃ£ nguá»“n má»Ÿ, máº¡nh máº½
- **MySQL**: Phá»• biáº¿n cho web
- **SQL Server**: Cá»§a Microsoft

## Nguá»“n tham kháº£o  
- https://example1.com
- https://example2.com

**Káº¾T QUáº¢ TÃŒM KIáº¾M:**
{content}

**CÃ‚U Há»I:** {query}

HÃ£y tráº£ lá»i dá»±a trÃªn thÃ´ng tin trÃªn vÃ  NHáº¤T Äá»ŠNH pháº£i cÃ³ pháº§n "## Nguá»“n tham kháº£o" á»Ÿ cuá»‘i vá»›i táº¥t cáº£ URL."""
    
    def _validate_llm_response(self, response: Any) -> str:
        """Validate vÃ  clean LLM response"""
        try:
            if hasattr(response, 'content'):
                content = response.content
            elif isinstance(response, str):
                content = response
            else:
                content = str(response)
            
            # Kiá»ƒm tra xem cÃ³ URL nguá»“n khÃ´ng
            if '[http' not in content and '[www' not in content:
                logger.warning("âš ï¸ LLM response thiáº¿u URL nguá»“n")
            
            return content.strip()
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i validate LLM response: {str(e)}")
            return "Lá»—i xá»­ lÃ½ pháº£n há»“i tá»« AI."
    
    def search_raw_results(self, query: str) -> Tuple[str, List[str]]:
        """
        TÃ¬m kiáº¿m vÃ  tráº£ vá» káº¿t quáº£ thÃ´ (khÃ´ng qua LLM processing)
        
        Args:
            query: CÃ¢u há»i cáº§n tÃ¬m kiáº¿m
            
        Returns:
            Tuple[str, List[str]]: (raw_search_content, source_urls)
        """
        try:
            # Validate query
            query = self._validate_query(query)
            
            # Check cache trÆ°á»›c
            cached_result = self.cache.get(query)
            if cached_result:
                return cached_result
            
            # Rate limiting
            if not self.rate_limiter.can_make_call():
                wait_time = self.rate_limiter.wait_time()
                logger.warning(f"â³ Rate limit reached. Äá»£i {wait_time:.1f}s...")
                time.sleep(wait_time)
            
            # Validate components
            if not self.llm or not self.tavily_search:
                error_msg = "âŒ Search components chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"
                logger.error(error_msg)
                return error_msg, []
            
            logger.info(f"ğŸ” Äang tÃ¬m kiáº¿m: {query[:100]}...")
            
            # Gá»i Tavily API
            start_time = time.time()
            results = self.tavily_search.invoke({"query": query})
            search_time = time.time() - start_time
            
            logger.info(f"ğŸ“Š Tavily search completed in {search_time:.2f}s")
            
            # Xá»­ lÃ½ káº¿t quáº£
            urls, content = self._process_tavily_results(results)
            
            if not content:
                no_result_msg = "ğŸ” KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n truy váº¥n nÃ y."
                logger.warning(no_result_msg)
                return no_result_msg, []
            
            # Tráº£ vá» káº¿t quáº£ thÃ´ (khÃ´ng qua LLM processing)
            # Cache káº¿t quáº£ thÃ´
            self.cache.set(query, content, urls)
            
            total_time = time.time() - start_time
            logger.info(f"âœ… Raw search hoÃ n thÃ nh trong {total_time:.2f}s vá»›i {len(urls)} nguá»“n")
            
            return content, urls
            
        except Exception as e:
            error_msg = f"âŒ Lá»—i tÃ¬m kiáº¿m: {str(e)}"
            logger.error(error_msg)
            return error_msg, []

    def search_with_sources(self, query: str) -> Tuple[str, List[str]]:
        """
        TÃ¬m kiáº¿m vá»›i sources vÃ  LLM processing (Ä‘á»ƒ backward compatibility)
        
        Args:
            query: CÃ¢u há»i cáº§n tÃ¬m kiáº¿m
            
        Returns:
            Tuple[str, List[str]]: (processed_answer, source_urls)
        """
        try:
            # Láº¥y káº¿t quáº£ thÃ´
            raw_content, urls = self.search_raw_results(query)
            
            if not raw_content or raw_content.startswith("ğŸ” KhÃ´ng tÃ¬m tháº¥y"):
                return raw_content, urls
            
            # Xá»­ lÃ½ vá»›i LLM náº¿u cáº§n
            prompt = self._create_optimized_prompt(query, raw_content)
            
            logger.info("ğŸ¤– Äang xá»­ lÃ½ vá»›i LLM...")
            llm_start = time.time()
            
            try:
                llm_response = self.llm.invoke(prompt)
                llm_time = time.time() - llm_start
                logger.info(f"ğŸ§  LLM processing completed in {llm_time:.2f}s")
                
                # Validate vÃ  clean response
                final_response = self._validate_llm_response(llm_response)
                return final_response, urls
                
            except Exception as llm_error:
                logger.error(f"âŒ LLM error: {str(llm_error)}")
                fallback_msg = f"Lá»—i xá»­ lÃ½ AI, nhÆ°ng Ä‘Ã£ tÃ¬m tháº¥y {len(urls)} nguá»“n liÃªn quan."
                return fallback_msg, urls
                
        except Exception as e:
            error_msg = f"âŒ Lá»—i tÃ¬m kiáº¿m: {str(e)}"
            logger.error(error_msg)
            return error_msg, []
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Láº¥y thá»‘ng kÃª cache"""
        return {
            "cache_size": len(self.cache.cache),
            "rate_limit_calls": len(self.rate_limiter.calls),
            "max_calls_per_minute": self.rate_limiter.max_calls
        }
    
    def clear_cache(self):
        """XÃ³a cache"""
        self.cache.cache.clear()
        logger.info("ğŸ—‘ï¸ Cache Ä‘Ã£ Ä‘Æ°á»£c xÃ³a")
    
    def cleanup_expired_cache(self):
        """Cleanup expired cache entries"""
        self.cache.clear_expired()

# Global instance
_search_instance = None

def get_search_instance(config: SearchConfig = SearchConfig()) -> OptimizedGoogleSearch:
    """Singleton pattern Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng instance"""
    global _search_instance
    if _search_instance is None:
        _search_instance = OptimizedGoogleSearch(config)
    return _search_instance

# Backwards compatibility functions
def tavily_with_sources(query: str) -> Tuple[List[str], str]:
    """Legacy function for backwards compatibility"""
    logger.warning("âš ï¸ Äang sá»­ dá»¥ng legacy function. Khuyáº¿n nghá»‹ dÃ¹ng OptimizedGoogleSearch class")
    search = get_search_instance()
    response, urls = search.search_with_sources(query)
    return urls, response

def run_query_with_sources(query: str) -> Tuple[Any, List[str]]:
    """Legacy function for backwards compatibility"""
    logger.warning("âš ï¸ Äang sá»­ dá»¥ng legacy function. Khuyáº¿n nghá»‹ dÃ¹ng OptimizedGoogleSearch class")
    search = get_search_instance()
    return search.search_with_sources(query)

def get_raw_search_results(query: str) -> Tuple[str, List[str]]:
    """Function to get raw search results without LLM processing"""
    search = get_search_instance()
    return search.search_raw_results(query)

# Main execution
if __name__ == "__main__":
    # Test vá»›i multiple queries
    test_queries = [
        "CÃº phÃ¡p select má»›i nháº¥t vÃ  Ä‘áº§y Ä‘á»§ cá»§a lá»‡nh select trong csdl?",
        "Best practices for database indexing in 2024",
        "KhÃ¡i niá»‡m ACID trong cÆ¡ sá»Ÿ dá»¯ liá»‡u"
    ]
    
    config = SearchConfig(
        max_results=3,
        cache_ttl_hours=1,  # Test cache
        rate_limit_per_minute=20
    )
    
    search = OptimizedGoogleSearch(config)
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” Query: {query}")
        print('='*60)
        
        start_time = time.time()
        response, sources = search.search_with_sources(query)
        elapsed = time.time() - start_time
        
        print(f"\nâ±ï¸ Thá»i gian: {elapsed:.2f}s")
        print(f"ğŸ“Š Sá»‘ nguá»“n: {len(sources)}")
        print(f"\nğŸ“ Káº¿t quáº£:\n{response}")
        print(f"\nğŸ”— Nguá»“n tham kháº£o:")
        for i, url in enumerate(sources, 1):
            print(f"  {i}. {url}")
        
        # Test cache láº§n 2
        print(f"\nğŸ”„ Testing cache...")
        start_time = time.time()
        cached_response, cached_sources = search.search_with_sources(query)
        cache_elapsed = time.time() - start_time
        print(f"âš¡ Cache hit time: {cache_elapsed:.3f}s")
    
    # Print cache stats
    stats = search.get_cache_stats()
    print(f"\nğŸ“Š Cache Stats: {stats}")
