{
  "session_id": "session_r2aqm3w5yq",
  "last_updated": "2025-05-09T16:10:01.571230",
  "messages": [
    {
      "role": "user",
      "content": "Read data trong hadoop là gì?"
    },
    {
      "role": "assistant",
      "content": "## Đọc Dữ Liệu trong Hadoop\n\n**Đọc dữ liệu trong Hadoop đề cập đến quá trình truy xuất dữ liệu từ Hadoop Distributed File System (HDFS) để xử lý hoặc phân tích.**\n\n### Quá trình Đọc Dữ Liệu\n\nQuá trình đọc dữ liệu từ HDFS bao gồm các bước sau:\n\n1.  **Client gửi yêu cầu mở file:** Client gọi phương thức `open()` ở `FileSystemObject` [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 9, Phần list].\n2.  **Truy vấn NameNode:** `DistributedFileSystem` gọi `NameNode` để lấy vị trí của các block của file [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 9, Phần list].\n3.  **Nhận thông tin DataNode:** `NameNode` trả về địa chỉ của các `DataNode` chứa bản sao của block đó [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 9, Phần list].\n4.  **Trả về FSDataInputStream:** Sau khi nhận được địa chỉ của các `NameNode`, một đối tượng `FSDataInputStream` được trả về cho client. `FSDataInputStream` chứa `DFSInputStream`. `DFSInputStream` quản lý I/O của `DataNode` và `NameNode` [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 10, Phần list].\n5.  **Đọc dữ liệu từ DataNode:** Client gọi phương thức `read()` ở `FSDataInputStream`, `DFSInputStream` kết nối với `DataNode` gần nhất để đọc block đầu tiên của file. Phương thức `read()` được lặp đi lặp lại nhiều lần cho đến cuối block [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 10, Phần list].\n6.  **Xử lý lỗi và chuyển đổi DataNode:** Sau khi đọc xong, `DFSInputStream` ngắt kết nối và xác định `DataNode` cho block tiếp theo. Khi `DFSInputStream` đọc file, nếu có lỗi xảy ra nó sẽ chuyển sang `DataNode` khác gần nhất có chứa block đó [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 10, Phần list].\n7.  **Đóng kết nối:** Khi client đọc xong file, gọi `close()` [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 10, Phần list].\n\n### Các Khái Niệm Liên Quan\n\n*   **HDFS (Hadoop Distributed File System):** Hệ thống lưu trữ phân tán của Hadoop, được thiết kế để lưu trữ và quản lý các tập dữ liệu lớn [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 3, Phần list].\n*   **NameNode:**  Nút chủ trong HDFS, quản lý không gian tên và metadata của hệ thống file [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 3, Phần list].\n*   **DataNode:** Nút làm việc trong HDFS, lưu trữ dữ liệu thực tế và thực hiện các thao tác I/O [Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 3, Phần list].\n*   **FSDataInputStream:** Cung cấp khả năng truy cập để đọc dữ liệu từ HDFS.\n*   **DFSInputStream:** Quản lý các tương tác I/O với NameNode và DataNode trong quá trình đọc dữ liệu.\n\n### Ví dụ\n\nTrong thực tế, người dùng thường không làm việc trực tiếp với HDFS bằng các câu lệnh mà thường đọc dữ liệu thông qua Spark, ví dụ:\n\n```scala\nval dataFrame = spark.read.load(\"<path_on_hadoop>\")\n```text\n\n[Nguồn: src/data\\Li_thuyet_Hadoop.pdf, Trang 9, Phần list]\n"
    }
  ]
}