from src.embeddings import initialize_embeddings
from src.loaders import DocumentLoader
from src.processors import DocumentProcessor, SQLDocumentProcessor
from src.processors.code_processor import CodeDocumentProcessor
from src.processors.table_processor import TableDocumentProcessor
from src.processors.pdf_processor import PDFDocumentProcessor
from src.vectorstore import VectorStoreManager
from src.retrieval import Retriever
from src.retrieval.hybrid_retriever import HybridRetriever
from src.llm import GeminiLLM
from src.fusion import RAGFusion
from src.query_expansion.query_decomposer import MultiStepReasoner
from src.templates import (
    get_database_query_prompt,
    get_sql_generation_prompt,
    get_schema_analysis_prompt,
)
from src.utils import measure_time, get_file_extension
from src.config import (
    QUERY_EXPANSION_ENABLED,
    RERANKER_ENABLED,
    SQL_FILE_EXTENSIONS,
    USE_HYBRID_SEARCH,
    USE_SELF_QUERY,
)
from typing import Dict, Any, Union, List
import time
import os
import re


class RAGPipeline:
    """L·ªõp ch√≠nh qu·∫£n l√Ω to√†n b·ªô pipeline RAG"""

    def __init__(self):
        """Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn c·ªßa pipeline"""
        print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Pipeline...")
        # Kh·ªüi t·∫°o v√† ki·ªÉm tra c√°c th√†nh ph·∫ßn c·ªßa pipeline
        self.embeddings = initialize_embeddings()

        # Kh·ªüi t·∫°o c√°c processor cho nhi·ªÅu lo·∫°i t√†i li·ªáu
        self.document_processor = DocumentProcessor(self.embeddings)
        self.sql_processor = SQLDocumentProcessor(self.embeddings)
        self.code_processor = CodeDocumentProcessor(self.embeddings)
        self.table_processor = TableDocumentProcessor(self.embeddings)
        self.pdf_processor = PDFDocumentProcessor(self.embeddings)

        # Kh·ªüi t·∫°o vector store
        self.vector_store_manager = VectorStoreManager(self.embeddings)
        self.vectorstore = self.vector_store_manager.get_vectorstore()

        # Kh·ªüi t·∫°o retriever (th√¥ng th∆∞·ªùng ho·∫∑c hybrid)
        if USE_HYBRID_SEARCH:
            print("‚è≥ ƒêang kh·ªüi t·∫°o HybridRetriever...")
            self.retriever = HybridRetriever(
                self.vectorstore, use_reranker=RERANKER_ENABLED
            )
            print("‚úÖ ƒê√£ kh·ªüi t·∫°o HybridRetriever!")
        else:
            self.retriever = Retriever(self.vectorstore)

        # Kh·ªüi t·∫°o RAG Fusion
        if QUERY_EXPANSION_ENABLED:
            try:
                print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Fusion...")
                self.fusion = RAGFusion(self.retriever)
                print("‚úÖ ƒê√£ kh·ªüi t·∫°o RAG Fusion!")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o RAG Fusion: {str(e)}")
                print("‚ö†Ô∏è S·∫Ω s·ª≠ d·ª•ng retriever th√¥ng th∆∞·ªùng")
                self.fusion = None
        else:
            self.fusion = None

        # Kh·ªüi t·∫°o MultiStepReasoner n·∫øu c·∫ßn thi·∫øt
        if USE_SELF_QUERY:
            print("‚è≥ ƒêang kh·ªüi t·∫°o MultiStepReasoner...")
            self.reasoner = MultiStepReasoner(self.retriever)
            print("‚úÖ ƒê√£ kh·ªüi t·∫°o MultiStepReasoner!")
        else:
            self.reasoner = None

        self.llm = GeminiLLM()
        print("‚úÖ RAG Pipeline ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")

    def _reinitialize_vectorstore(self):
        """Kh·ªüi t·∫°o l·∫°i vectorstore v√† retriever"""
        print("üîÑ ƒêang kh·ªüi t·∫°o l·∫°i vector store...")
        self.vectorstore = self.vector_store_manager.get_vectorstore()

        # L∆∞u reranker c≈© n·∫øu c√≥
        old_reranker = None
        if (
            hasattr(self, "retriever")
            and self.retriever
            and hasattr(self.retriever, "reranker")
        ):
            old_reranker = self.retriever.reranker

        # Kh·ªüi t·∫°o retriever m·ªõi nh∆∞ng d√πng l·∫°i reranker c≈© n·∫øu c√≥
        if USE_HYBRID_SEARCH:
            self.retriever = HybridRetriever(
                self.vectorstore, use_reranker=RERANKER_ENABLED
            )

            # X√¢y d·ª±ng sparse index n·∫øu l√† hybrid retriever
            try:
                documents = self.vector_store_manager.get_all_documents()
                if documents:
                    print(
                        f"‚è≥ ƒêang x√¢y d·ª±ng sparse index cho {len(documents)} t√†i li·ªáu..."
                    )
                    self.retriever.build_sparse_index(documents)
                else:
                    print(
                        "‚ÑπÔ∏è Kh√¥ng c√≥ t√†i li·ªáu n√†o trong vector store ƒë·ªÉ x√¢y d·ª±ng sparse index"
                    )
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y t√†i li·ªáu ƒë·ªÉ x√¢y d·ª±ng sparse index: {str(e)}")
        else:
            self.retriever = Retriever(self.vectorstore, use_reranker=RERANKER_ENABLED)

        # G√°n l·∫°i reranker c≈© n·∫øu c√≥
        if (
            old_reranker is not None
            and hasattr(self.retriever, "use_reranker")
            and self.retriever.use_reranker
        ):
            print("‚ÑπÔ∏è T√°i s·ª≠ d·ª•ng reranker ƒë√£ kh·ªüi t·∫°o tr∆∞·ªõc ƒë√≥")
            self.retriever.reranker = old_reranker

        # Kh·ªüi t·∫°o l·∫°i fusion n·∫øu c√≥
        if QUERY_EXPANSION_ENABLED and hasattr(self, "fusion") and self.fusion:
            self.fusion = RAGFusion(self.retriever)

        # C·∫≠p nh·∫≠t l·∫°i reasoner ƒë·ªÉ s·ª≠ d·ª•ng retriever m·ªõi
        if USE_SELF_QUERY and hasattr(self, "reasoner") and self.reasoner:
            self.reasoner.retriever = self.retriever

        print("‚úÖ ƒê√£ kh·ªüi t·∫°o l·∫°i vector store!")

    @measure_time
    def index_data(self, data_directory: str):
        """Th·ª±c hi·ªán qu√° tr√¨nh indexing d·ªØ li·ªáu"""
        # 1. Load t√†i li·ªáu
        documents = DocumentLoader.load_documents(data_directory)

        # 2. Ph√¢n chia t√†i li·ªáu theo lo·∫°i
        sql_docs = []
        code_docs = []
        table_docs = []
        pdf_docs = []
        regular_docs = []

        for doc in documents:
            source_path = doc.metadata.get("source_path", "")
            ext = get_file_extension(source_path)

            # Ph√¢n lo·∫°i theo extension
            if ext in SQL_FILE_EXTENSIONS:
                sql_docs.append(doc)
            elif ext in [
                ".py",
                ".js",
                ".ts",
                ".jsx",
                ".tsx",
                ".java",
                ".cs",
                ".cpp",
                ".c",
                ".h",
            ]:
                code_docs.append(doc)
            elif ext in [".csv", ".xlsx", ".xls", ".json", ".tsv"]:
                table_docs.append(doc)
            elif ext == ".pdf":
                pdf_docs.append(doc)
            else:
                regular_docs.append(doc)

        print(
            f"‚ÑπÔ∏è T·ªïng s·ªë t√†i li·ªáu: {len(documents)} "
            f"(SQL: {len(sql_docs)}, Code: {len(code_docs)}, "
            f"Table: {len(table_docs)}, PDF: {len(pdf_docs)}, "
            f"Th√¥ng th∆∞·ªùng: {len(regular_docs)})"
        )

        # 3a. X·ª≠ l√Ω c√°c t√†i li·ªáu SQL v·ªõi processor ƒë·∫∑c bi·ªát
        if sql_docs:
            print("‚è≥ ƒêang x·ª≠ l√Ω c√°c t√†i li·ªáu SQL...")
            sql_chunks = self.sql_processor.process_sql_documents(sql_docs)
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(sql_chunks)} chunks t·ª´ {len(sql_docs)} t√†i li·ªáu SQL"
            )
        else:
            sql_chunks = []

        # 3b. X·ª≠ l√Ω c√°c t√†i li·ªáu code v·ªõi processor ƒë·∫∑c bi·ªát
        if code_docs:
            print("‚è≥ ƒêang x·ª≠ l√Ω c√°c t√†i li·ªáu code...")
            code_chunks = self.code_processor.process_code_documents(code_docs)
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(code_chunks)} chunks t·ª´ {len(code_docs)} t√†i li·ªáu code"
            )
        else:
            code_chunks = []

        # 3c. X·ª≠ l√Ω c√°c t√†i li·ªáu d·∫°ng b·∫£ng v·ªõi processor ƒë·∫∑c bi·ªát
        if table_docs:
            print("‚è≥ ƒêang x·ª≠ l√Ω c√°c t√†i li·ªáu d·∫°ng b·∫£ng...")
            table_chunks = self.table_processor.process_table_documents(table_docs)
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(table_chunks)} chunks t·ª´ {len(table_docs)} t√†i li·ªáu d·∫°ng b·∫£ng"
            )
        else:
            table_chunks = []

        # 3d. X·ª≠ l√Ω c√°c t√†i li·ªáu PDF v·ªõi processor ƒë·∫∑c bi·ªát
        if pdf_docs:
            print("‚è≥ ƒêang x·ª≠ l√Ω c√°c t√†i li·ªáu PDF...")
            pdf_chunks = self.pdf_processor.process_pdf_documents(pdf_docs)
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(pdf_chunks)} chunks t·ª´ {len(pdf_docs)} t√†i li·ªáu PDF"
            )
        else:
            pdf_chunks = []

        # 3e. X·ª≠ l√Ω c√°c t√†i li·ªáu th√¥ng th∆∞·ªùng v·ªõi processor th√¥ng th∆∞·ªùng
        if regular_docs:
            # Chunk t√†i li·ªáu th√¥ng th∆∞·ªùng
            regular_chunks = self.document_processor.chunk_documents(regular_docs)
            # Cluster & merge ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng
            merged_regular_chunks = self.document_processor.cluster_and_merge(
                regular_chunks
            )
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(merged_regular_chunks)} chunks t·ª´ {len(regular_docs)} t√†i li·ªáu th√¥ng th∆∞·ªùng"
            )
        else:
            merged_regular_chunks = []

        # 4. K·∫øt h·ª£p t·∫•t c·∫£ chunks
        all_chunks = (
            sql_chunks + code_chunks + table_chunks + pdf_chunks + merged_regular_chunks
        )
        print(f"‚ÑπÔ∏è T·ªïng s·ªë chunks ƒë·ªÉ index: {len(all_chunks)}")

        # 5. Upload v√†o vector store
        self.vector_store_manager.upload_documents(all_chunks)

        # Kh·ªüi t·∫°o l·∫°i vectorstore ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
        self._reinitialize_vectorstore()

        print("‚úÖ Ho√†n th√†nh qu√° tr√¨nh indexing d·ªØ li·ªáu")

    @measure_time
    def delete_file(self, file_path: str) -> int:
        """X√≥a file v√† c√°c embedding t∆∞∆°ng ·ª©ng kh·ªèi vector store

        Args:
            file_path: ƒê∆∞·ªùng d·∫´n t·ªõi file c·∫ßn x√≥a

        Returns:
            S·ªë l∆∞·ª£ng point ƒë√£ x√≥a
        """
        # X√≥a c√°c point trong vector store
        deleted_count = self.vector_store_manager.delete_points_by_file(file_path)

        # ƒê·∫∑t l·∫°i tr·∫°ng th√°i vectorstore v·ªÅ None
        if deleted_count > 0:
            self.vectorstore = None

        print(f"‚úÖ ƒê√£ x√≥a {deleted_count} point li√™n quan ƒë·∫øn file: {file_path}")

        return deleted_count

    @measure_time
    def delete_index(self, collection_name=None):
        """X√≥a to√†n b·ªô index trong vector store"""
        # X√≥a collection
        self.vector_store_manager.delete_collection(collection_name)

        # ƒê·∫∑t l·∫°i tr·∫°ng th√°i vectorstore v·ªÅ None
        self.vectorstore = None

        print(
            "‚ö†Ô∏è Vector store ƒë√£ b·ªã x√≥a. B·∫°n c·∫ßn t·∫°o l·∫°i index tr∆∞·ªõc khi th·ª±c hi·ªán truy v·∫•n."
        )

    def _select_prompt_template(self, query: str, docs: List[Any]) -> str:
        """Ch·ªçn template prompt ph√π h·ª£p d·ª±a tr√™n n·ªôi dung query v√† t√†i li·ªáu

        Args:
            query: C√¢u truy v·∫•n
            docs: Danh s√°ch t√†i li·ªáu li√™n quan

        Returns:
            Template prompt ph√π h·ª£p
        """
        # Ph√°t hi·ªán y√™u c·∫ßu t·∫°o SQL
        sql_generation_keywords = [
            "vi·∫øt sql",
            "t·∫°o sql",
            "generate sql",
            "create query",
            "write a query",
            "vi·∫øt truy v·∫•n",
        ]
        if any(kw in query.lower() for kw in sql_generation_keywords):
            return get_sql_generation_prompt

        # Ph√°t hi·ªán ph√¢n t√≠ch schema
        schema_keywords = [
            "ph√¢n t√≠ch schema",
            "analyze schema",
            "ƒë√°nh gi√° thi·∫øt k·∫ø",
            "evaluate design",
            "database design",
        ]
        if any(kw in query.lower() for kw in schema_keywords):
            return get_schema_analysis_prompt

        # Ph√°t hi·ªán t√†i li·ªáu SQL trong context
        has_sql_docs = False
        for doc in docs:
            if "sql_document_type" in doc.metadata or "sql_type" in doc.metadata:
                has_sql_docs = True
                break

        # S·ª≠ d·ª•ng prompt CSDL n·∫øu c√≥ t√†i li·ªáu SQL
        if has_sql_docs:
            return get_database_query_prompt

        # M·∫∑c ƒë·ªãnh d√πng prompt c∆° s·ªü d·ªØ li·ªáu v√¨ ƒë√¢y l√† h·ªá th·ªëng chuy√™n v·ªÅ CSDL
        return get_database_query_prompt

    def _process_sql_in_response(self, text: str) -> str:
        """X·ª≠ l√Ω v√† ƒë√°nh d·∫•u c√°c ƒëo·∫°n code SQL trong c√¢u tr·∫£ l·ªùi

        Args:
            text: VƒÉn b·∫£n c√¢u tr·∫£ l·ªùi t·ª´ LLM

        Returns:
            VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v·ªõi c√°c ƒëo·∫°n code SQL ƒë∆∞·ª£c ƒë√°nh d·∫•u
        """
        # Pattern ƒë·ªÉ t√¨m c√°c ƒëo·∫°n code n·∫±m gi·ªØa c√°c d·∫•u backtick ho·∫∑c trong block code
        # C·∫ßn x·ª≠ l√Ω c·∫£ 2 tr∆∞·ªùng h·ª£p:
        # 1. ```sql ... ``` ho·∫∑c ```SQL ... ```
        # 2. ```... c√°c l·ªánh SQL ...```
        # 3. `... c√°c l·ªánh SQL ...`

        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p code block c√≥ ƒë√°nh d·∫•u SQL
        sql_block_pattern = r"```(?:sql|SQL)(.*?)```"
        # T√¨m t·∫•t c·∫£ c√°c kh·ªëi code ƒë√£ ƒë∆∞·ª£c ƒë√°nh d·∫•u sql v√† ƒë·∫£m b·∫£o r·∫±ng ch√∫ng v·∫´n ƒë∆∞·ª£c ƒë√°nh d·∫•u ƒë√∫ng
        processed_text = re.sub(
            sql_block_pattern, r"```sql\1```", text, flags=re.DOTALL
        )

        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p code block kh√¥ng ƒë√°nh d·∫•u c·ª• th·ªÉ ng√¥n ng·ªØ
        unmarked_block_pattern = r"```(?!\w)(.*?)```"

        def process_unmarked_block(match):
            content = match.group(1)
            # Ki·ªÉm tra xem kh·ªëi n√†y c√≥ ph·∫£i l√† SQL hay kh√¥ng
            sql_keywords = [
                r"\bSELECT\b",
                r"\bFROM\b",
                r"\bWHERE\b",
                r"\bJOIN\b",
                r"\bGROUP BY\b",
                r"\bORDER BY\b",
                r"\bHAVING\b",
                r"\bUNION\b",
                r"\bINSERT INTO\b",
                r"\bVALUES\b",
                r"\bUPDATE\b",
                r"\bSET\b",
                r"\bDELETE FROM\b",
                r"\bCREATE TABLE\b",
                r"\bALTER TABLE\b",
                r"\bDROP TABLE\b",
                r"\bINDEX\b",
                r"\bTRIGGER\b",
                r"\bVIEW\b",
            ]

            # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ kh√≥a SQL trong n·ªôi dung
            sql_keyword_count = sum(
                1
                for keyword in sql_keywords
                if re.search(keyword, content, re.IGNORECASE)
            )

            # N·∫øu c√≥ √≠t nh·∫•t 2 t·ª´ kh√≥a SQL ph·ªï bi·∫øn, th√¨ ƒë√°nh d·∫•u l√† SQL
            if sql_keyword_count >= 2:
                return f"```sql{content}```"
            return f"```{content}```"

        # √Åp d·ª•ng x·ª≠ l√Ω cho c√°c code block kh√¥ng ƒë√°nh d·∫•u
        processed_text = re.sub(
            unmarked_block_pattern,
            process_unmarked_block,
            processed_text,
            flags=re.DOTALL,
        )

        # X·ª≠ l√Ω c√°c ƒëo·∫°n code n·∫±m trong d·∫•u backtick ƒë∆°n
        inline_code_pattern = r"`([^`]+)`"

        def process_inline_code(match):
            content = match.group(1)
            # Ki·ªÉm tra t·ª´ kh√≥a SQL ph·ªï bi·∫øn
            sql_keywords = [
                "SELECT",
                "FROM",
                "WHERE",
                "JOIN",
                "INSERT",
                "UPDATE",
                "DELETE",
            ]

            # N·∫øu ƒëo·∫°n code inline c√≥ v·∫ª l√† m·ªôt c√¢u l·ªánh SQL ƒë∆°n gi·∫£n
            if any(
                keyword in content.upper() for keyword in sql_keywords
            ) and re.search(
                r"\b(SELECT|INSERT|UPDATE|DELETE)\b", content, re.IGNORECASE
            ):
                # Chuy·ªÉn ƒë·ªïi th√†nh d·∫•u backtick triple n·∫øu l√† SQL
                return f"```sql\n{content}\n```"
            return f"`{content}`"

        # √Åp d·ª•ng x·ª≠ l√Ω cho c√°c ƒëo·∫°n code inline
        processed_text = re.sub(
            inline_code_pattern, process_inline_code, processed_text
        )

        return processed_text

    @measure_time
    def query(self, query_text: str) -> Dict[str, Any]:
        """Truy v·∫•n RAG Pipeline

        Args:
            query_text: C√¢u truy v·∫•n ng∆∞·ªùi d√πng

        Returns:
            Dict ch·ª©a c√¢u tr·∫£ l·ªùi v√† c√°c th√¥ng tin b·ªï sung
        """
        # Kh·ªüi t·∫°o k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh
        result = {
            "text": "",
            "sources": [],
            "prompt": "",
            "query": query_text,
            "model": "",
            "temperature": 0.0,
            "total_sources": 0,
            "retrieval_time": 0.0,
            "llm_time": 0.0,
        }

        # Ki·ªÉm tra xem collection c√≥ t·ªìn t·∫°i kh√¥ng
        if not self.vector_store_manager.client.collection_exists(
            self.vector_store_manager.collection_name
        ):
            print(
                f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} kh√¥ng t·ªìn t·∫°i. Vui l√≤ng t·∫°o index tr∆∞·ªõc."
            )
            result["text"] = (
                "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng t·∫°o index tr∆∞·ªõc b·∫±ng l·ªánh: python -m src.main index --data-dir ./data"
            )
            return result

        # ƒê·∫£m b·∫£o vectorstore ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        if self.vectorstore is None:
            self._reinitialize_vectorstore()
            # N·∫øu v·∫´n kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c
            if self.vectorstore is None:
                result["text"] = (
                    "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn vector store. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh v√† k·∫øt n·ªëi."
                )
                return result

        # Ki·ªÉm tra xem collection c√≥ ch·ª©a d·ªØ li·ªáu kh√¥ng
        try:
            collection_info = self.vector_store_manager.client.get_collection(
                self.vector_store_manager.collection_name
            )
            vector_count = collection_info.vectors_count
            if vector_count == 0:
                print(
                    f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} r·ªóng (0 vectors)"
                )
                result["text"] = (
                    "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu trong vector store. Vui l√≤ng upload v√† index t√†i li·ªáu tr∆∞·ªõc."
                )
                return result
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ki·ªÉm tra d·ªØ li·ªáu trong collection: {str(e)}")
            result["text"] = f"L·ªói khi ki·ªÉm tra d·ªØ li·ªáu: {str(e)}"
            return result

        # 1. Ki·ªÉm tra n·∫øu c·∫ßn s·ª≠ d·ª•ng multi-step reasoning
        if USE_SELF_QUERY and self.reasoner:
            is_complex = self.reasoner.decomposer._is_complex_query(query_text)
            if is_complex:
                print(f"‚ÑπÔ∏è Ph√°t hi·ªán truy v·∫•n ph·ª©c t·∫°p, s·ª≠ d·ª•ng multi-step reasoning")
                reasoning_result = self.reasoner.answer_with_reasoning(query_text)

                # X·ª≠ l√Ω v√† ƒë√°nh d·∫•u code SQL trong c√¢u tr·∫£ l·ªùi
                reasoning_result["answer"] = self._process_sql_in_response(
                    reasoning_result["answer"]
                )

                result["text"] = reasoning_result["answer"]
                result["reasoning_steps"] = reasoning_result.get("reasoning_steps", [])
                result["retrieval_time"] = 0
                result["llm_time"] = 0
                result["used_reasoning"] = True

                return result

        # 2. L·∫•y t√†i li·ªáu li√™n quan
        retrieval_start = time.time()

        # S·ª≠ d·ª•ng RAG Fusion n·∫øu ƒë∆∞·ª£c b·∫≠t, n·∫øu kh√¥ng s·ª≠ d·ª•ng retriever th√¥ng th∆∞·ªùng
        if self.fusion and QUERY_EXPANSION_ENABLED:
            # S·ª≠ d·ª•ng fusion.retrieve() trong FAST_MODE ƒë·ªÉ tr√°nh rerank hai l·∫ßn
            # fusion.retrieve s·∫Ω t·ª± ƒë·ªông s·ª≠ d·ª•ng reranker n·∫øu RERANK_RETRIEVAL_RESULTS=True
            relevant_docs = self.fusion.retrieve(query_text)
        else:
            # N·∫øu s·ª≠ d·ª•ng HybridRetriever, retrieve ƒë√£ ƒë∆∞·ª£c override ƒë·ªÉ s·ª≠ d·ª•ng hybrid_retrieve
            relevant_docs = self.retriever.retrieve(query_text)

        retrieval_end = time.time()
        result["retrieval_time"] = retrieval_end - retrieval_start

        # 3. T·∫°o c√¢u tr·∫£ l·ªùi v·ªõi LLM
        llm_start = time.time()

        # Ch·ªçn prompt template ph√π h·ª£p
        prompt_template = self._select_prompt_template(query_text, relevant_docs)

        # T·∫°o response v·ªõi LLM
        response_dict = self.llm.generate_response(
            query_text, relevant_docs, prompt_template=prompt_template
        )

        llm_end = time.time()
        result["llm_time"] = llm_end - llm_start

        # 4. G·ªôp k·∫øt qu·∫£ t·ª´ LLM v√†o k·∫øt qu·∫£ cu·ªëi c√πng
        result.update(response_dict)

        # 5. X·ª≠ l√Ω v√† ƒë√°nh d·∫•u code SQL trong c√¢u tr·∫£ l·ªùi
        if "text" in result and result["text"]:
            result["text"] = self._process_sql_in_response(result["text"])

        # 6. B·ªï sung th√¥ng tin th√™m
        result["query"] = query_text
        result["total_tokens"] = len(query_text.split()) + len(result["text"].split())
        result["used_reasoning"] = False

        # Th√™m th√¥ng tin v·ªÅ ph∆∞∆°ng ph√°p retrieval ƒë√£ s·ª≠ d·ª•ng
        result["retrieval_method"] = "hybrid" if USE_HYBRID_SEARCH else "vector"
        if self.fusion and QUERY_EXPANSION_ENABLED:
            result["retrieval_method"] += "_fusion"

        return result
