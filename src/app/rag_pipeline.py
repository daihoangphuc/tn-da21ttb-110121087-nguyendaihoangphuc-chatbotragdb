from src.embeddings import initialize_embeddings
from src.loaders import DocumentLoader
from src.processors import DocumentProcessor
from src.vectorstore import VectorStoreManager
from src.retrieval import Retriever
from src.llm import GeminiLLM
from src.utils import measure_time
from typing import Dict, Any, Union
import time


class RAGPipeline:
    """L·ªõp ch√≠nh qu·∫£n l√Ω to√†n b·ªô pipeline RAG"""

    def __init__(self):
        """Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn c·ªßa pipeline"""
        print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Pipeline...")
        # Kh·ªüi t·∫°o v√† ki·ªÉm tra c√°c th√†nh ph·∫ßn c·ªßa pipeline
        self.embeddings = initialize_embeddings()
        self.processor = DocumentProcessor(self.embeddings)
        self.vector_store_manager = VectorStoreManager(self.embeddings)
        self.vectorstore = self.vector_store_manager.get_vectorstore()
        self.retriever = Retriever(self.vectorstore)
        self.llm = GeminiLLM()
        print("‚úÖ RAG Pipeline ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")

    def _reinitialize_vectorstore(self):
        """Kh·ªüi t·∫°o l·∫°i vectorstore v√† retriever"""
        print("üîÑ ƒêang kh·ªüi t·∫°o l·∫°i vector store...")
        self.vectorstore = self.vector_store_manager.get_vectorstore()
        self.retriever = Retriever(self.vectorstore)
        print("‚úÖ ƒê√£ kh·ªüi t·∫°o l·∫°i vector store!")

    @measure_time
    def index_data(self, data_directory: str):
        """Th·ª±c hi·ªán qu√° tr√¨nh indexing d·ªØ li·ªáu"""
        # 1. Load t√†i li·ªáu
        documents = DocumentLoader.load_documents(data_directory)

        # 2. Chunk t√†i li·ªáu
        chunks = self.processor.chunk_documents(documents)

        # 3. Cluster & merge ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng
        merged_docs = self.processor.cluster_and_merge(chunks)

        # 4. Upload v√†o vector store
        self.vector_store_manager.upload_documents(merged_docs)

        # Kh·ªüi t·∫°o l·∫°i vectorstore ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
        self._reinitialize_vectorstore()

        print("‚úÖ Ho√†n th√†nh qu√° tr√¨nh indexing d·ªØ li·ªáu")

    @measure_time
    def delete_file(self, file_path: str) -> int:
        """X√≥a file v√† c√°c embedding t∆∞∆°ng ·ª©ng kh·ªèi vector store

        Args:
            file_path: ƒê∆∞·ªùng d·∫´n t·ªõi file c·∫ßn x√≥a

        Returns:
            S·ªë l∆∞·ª£ng point ƒë√£ x√≥a
        """
        # X√≥a c√°c point trong vector store
        deleted_count = self.vector_store_manager.delete_points_by_file(file_path)

        # Kh·ªüi t·∫°o l·∫°i vectorstore n·∫øu c√≥ point b·ªã x√≥a
        if deleted_count > 0:
            self._reinitialize_vectorstore()

        print(f"‚úÖ ƒê√£ x√≥a {deleted_count} point li√™n quan ƒë·∫øn file: {file_path}")

        return deleted_count

    @measure_time
    def delete_index(self, collection_name=None):
        """X√≥a to√†n b·ªô index trong vector store"""
        self.vector_store_manager.delete_collection(collection_name)
        # Kh·ªüi t·∫°o l·∫°i vectorstore
        self._reinitialize_vectorstore()
        print("‚ö†Ô∏è L∆∞u √Ω: B·∫°n c·∫ßn t·∫°o l·∫°i index tr∆∞·ªõc khi th·ª±c hi·ªán truy v·∫•n.")

    @measure_time
    def query(self, query_text: str) -> Dict[str, Any]:
        """Truy v·∫•n RAG Pipeline

        Args:
            query_text: C√¢u truy v·∫•n ng∆∞·ªùi d√πng

        Returns:
            Dict ch·ª©a c√¢u tr·∫£ l·ªùi v√† c√°c th√¥ng tin b·ªï sung
        """
        # Kh·ªüi t·∫°o k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh
        result = {
            "text": "",
            "sources": [],
            "prompt": "",
            "query": query_text,
            "model": "",
            "temperature": 0.0,
            "total_sources": 0,
            "retrieval_time": 0.0,
            "llm_time": 0.0,
        }

        # Ki·ªÉm tra xem collection c√≥ t·ªìn t·∫°i kh√¥ng
        if not self.vector_store_manager.client.collection_exists(
            self.vector_store_manager.collection_name
        ):
            print(
                f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} kh√¥ng t·ªìn t·∫°i. Vui l√≤ng t·∫°o index tr∆∞·ªõc."
            )
            result["text"] = (
                "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng t·∫°o index tr∆∞·ªõc b·∫±ng l·ªánh: python -m src.main index --data-dir ./data"
            )
            return result

        # ƒê·∫£m b·∫£o vectorstore ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        if self.vectorstore is None:
            self._reinitialize_vectorstore()
            # N·∫øu v·∫´n kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c
            if self.vectorstore is None:
                result["text"] = (
                    "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn vector store. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh v√† k·∫øt n·ªëi."
                )
                return result

        # Ki·ªÉm tra xem collection c√≥ ch·ª©a d·ªØ li·ªáu kh√¥ng
        try:
            collection_info = self.vector_store_manager.client.get_collection(
                self.vector_store_manager.collection_name
            )
            vector_count = collection_info.vectors_count
            if vector_count == 0:
                print(
                    f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} r·ªóng (0 vectors)"
                )
                result["text"] = (
                    "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu trong vector store. Vui l√≤ng upload v√† index t√†i li·ªáu tr∆∞·ªõc."
                )
                return result
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ki·ªÉm tra d·ªØ li·ªáu trong collection: {str(e)}")
            result["text"] = f"L·ªói khi ki·ªÉm tra d·ªØ li·ªáu: {str(e)}"
            return result

        # 1. L·∫•y t√†i li·ªáu li√™n quan
        retrieval_start = time.time()
        relevant_docs = self.retriever.retrieve(query_text)
        retrieval_end = time.time()
        result["retrieval_time"] = retrieval_end - retrieval_start

        # 2. T·∫°o c√¢u tr·∫£ l·ªùi v·ªõi LLM
        llm_start = time.time()
        response_dict = self.llm.generate_response(query_text, relevant_docs)
        llm_end = time.time()
        result["llm_time"] = llm_end - llm_start

        # 3. G·ªôp k·∫øt qu·∫£ t·ª´ LLM v√†o k·∫øt qu·∫£ cu·ªëi c√πng
        result.update(response_dict)

        # 4. B·ªï sung th√¥ng tin th√™m
        result["query"] = query_text
        result["total_tokens"] = len(query_text.split()) + len(result["text"].split())

        return result
