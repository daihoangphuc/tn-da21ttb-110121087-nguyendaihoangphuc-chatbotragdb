from src.embeddings import initialize_embeddings
from src.loaders import DocumentLoader
from src.processors import DocumentProcessor, SQLDocumentProcessor
from src.vectorstore import VectorStoreManager
from src.retrieval import Retriever
from src.llm import GeminiLLM
from src.fusion import RAGFusion
from src.templates import (
    get_database_query_prompt,
    get_sql_generation_prompt,
    get_schema_analysis_prompt,
)
from src.utils import measure_time, get_file_extension
from src.config import QUERY_EXPANSION_ENABLED, RERANKER_ENABLED, SQL_FILE_EXTENSIONS
from typing import Dict, Any, Union, List
import time
import os


class RAGPipeline:
    """L·ªõp ch√≠nh qu·∫£n l√Ω to√†n b·ªô pipeline RAG"""

    def __init__(self):
        """Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn c·ªßa pipeline"""
        print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Pipeline...")
        # Kh·ªüi t·∫°o v√† ki·ªÉm tra c√°c th√†nh ph·∫ßn c·ªßa pipeline
        self.embeddings = initialize_embeddings()
        self.document_processor = DocumentProcessor(self.embeddings)
        self.sql_processor = SQLDocumentProcessor(self.embeddings)
        self.vector_store_manager = VectorStoreManager(self.embeddings)
        self.vectorstore = self.vector_store_manager.get_vectorstore()
        self.retriever = Retriever(self.vectorstore)

        # Kh·ªüi t·∫°o RAG Fusion
        if QUERY_EXPANSION_ENABLED:
            try:
                print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Fusion...")
                self.fusion = RAGFusion(self.retriever)
                print("‚úÖ ƒê√£ kh·ªüi t·∫°o RAG Fusion!")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o RAG Fusion: {str(e)}")
                print("‚ö†Ô∏è S·∫Ω s·ª≠ d·ª•ng retriever th√¥ng th∆∞·ªùng")
                self.fusion = None
        else:
            self.fusion = None

        self.llm = GeminiLLM()
        print("‚úÖ RAG Pipeline ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")

    def _reinitialize_vectorstore(self):
        """Kh·ªüi t·∫°o l·∫°i vectorstore v√† retriever"""
        print("üîÑ ƒêang kh·ªüi t·∫°o l·∫°i vector store...")
        self.vectorstore = self.vector_store_manager.get_vectorstore()

        # L∆∞u reranker c≈© n·∫øu c√≥
        old_reranker = None
        if (
            hasattr(self, "retriever")
            and self.retriever
            and hasattr(self.retriever, "reranker")
        ):
            old_reranker = self.retriever.reranker

        # Kh·ªüi t·∫°o retriever m·ªõi nh∆∞ng d√πng l·∫°i reranker c≈© n·∫øu c√≥
        self.retriever = Retriever(self.vectorstore, use_reranker=RERANKER_ENABLED)

        # G√°n l·∫°i reranker c≈© n·∫øu c√≥
        if (
            old_reranker is not None
            and hasattr(self.retriever, "use_reranker")
            and self.retriever.use_reranker
        ):
            print("‚ÑπÔ∏è T√°i s·ª≠ d·ª•ng reranker ƒë√£ kh·ªüi t·∫°o tr∆∞·ªõc ƒë√≥")
            self.retriever.reranker = old_reranker

        # Kh·ªüi t·∫°o l·∫°i fusion n·∫øu c√≥
        if QUERY_EXPANSION_ENABLED and hasattr(self, "fusion") and self.fusion:
            self.fusion = RAGFusion(self.retriever)

        print("‚úÖ ƒê√£ kh·ªüi t·∫°o l·∫°i vector store!")

    @measure_time
    def index_data(self, data_directory: str):
        """Th·ª±c hi·ªán qu√° tr√¨nh indexing d·ªØ li·ªáu"""
        # 1. Load t√†i li·ªáu
        documents = DocumentLoader.load_documents(data_directory)

        # 2. Ph√¢n chia t√†i li·ªáu theo lo·∫°i
        sql_docs = []
        regular_docs = []

        for doc in documents:
            # Ph√°t hi·ªán t√†i li·ªáu SQL d·ª±a tr√™n ph·∫ßn m·ªü r·ªông file
            ext = get_file_extension(doc.metadata.get("source_path", ""))
            if ext in SQL_FILE_EXTENSIONS:
                sql_docs.append(doc)
            else:
                regular_docs.append(doc)

        print(
            f"‚ÑπÔ∏è T·ªïng s·ªë t√†i li·ªáu: {len(documents)} (SQL: {len(sql_docs)}, Th√¥ng th∆∞·ªùng: {len(regular_docs)})"
        )

        # 3a. X·ª≠ l√Ω c√°c t√†i li·ªáu SQL v·ªõi processor ƒë·∫∑c bi·ªát
        if sql_docs:
            print("‚è≥ ƒêang x·ª≠ l√Ω c√°c t√†i li·ªáu SQL...")
            sql_chunks = self.sql_processor.process_sql_documents(sql_docs)
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(sql_chunks)} chunks t·ª´ {len(sql_docs)} t√†i li·ªáu SQL"
            )
        else:
            sql_chunks = []

        # 3b. X·ª≠ l√Ω c√°c t√†i li·ªáu th√¥ng th∆∞·ªùng v·ªõi processor th√¥ng th∆∞·ªùng
        if regular_docs:
            # Chunk t√†i li·ªáu th√¥ng th∆∞·ªùng
            regular_chunks = self.document_processor.chunk_documents(regular_docs)
            # Cluster & merge ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng
            merged_regular_chunks = self.document_processor.cluster_and_merge(
                regular_chunks
            )
            print(
                f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(merged_regular_chunks)} chunks t·ª´ {len(regular_docs)} t√†i li·ªáu th√¥ng th∆∞·ªùng"
            )
        else:
            merged_regular_chunks = []

        # 4. K·∫øt h·ª£p t·∫•t c·∫£ chunks
        all_chunks = sql_chunks + merged_regular_chunks
        print(f"‚ÑπÔ∏è T·ªïng s·ªë chunks ƒë·ªÉ index: {len(all_chunks)}")

        # 5. Upload v√†o vector store
        self.vector_store_manager.upload_documents(all_chunks)

        # Kh·ªüi t·∫°o l·∫°i vectorstore ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
        self._reinitialize_vectorstore()

        print("‚úÖ Ho√†n th√†nh qu√° tr√¨nh indexing d·ªØ li·ªáu")

    @measure_time
    def delete_file(self, file_path: str) -> int:
        """X√≥a file v√† c√°c embedding t∆∞∆°ng ·ª©ng kh·ªèi vector store

        Args:
            file_path: ƒê∆∞·ªùng d·∫´n t·ªõi file c·∫ßn x√≥a

        Returns:
            S·ªë l∆∞·ª£ng point ƒë√£ x√≥a
        """
        # X√≥a c√°c point trong vector store
        deleted_count = self.vector_store_manager.delete_points_by_file(file_path)

        # Kh·ªüi t·∫°o l·∫°i vectorstore n·∫øu c√≥ point b·ªã x√≥a
        if deleted_count > 0:
            self._reinitialize_vectorstore()

        print(f"‚úÖ ƒê√£ x√≥a {deleted_count} point li√™n quan ƒë·∫øn file: {file_path}")

        return deleted_count

    @measure_time
    def delete_index(self, collection_name=None):
        """X√≥a to√†n b·ªô index trong vector store"""
        # X√≥a collection
        self.vector_store_manager.delete_collection(collection_name)

        # ƒê·∫∑t l·∫°i tr·∫°ng th√°i vectorstore v·ªÅ None
        self.vectorstore = None

        print(
            "‚ö†Ô∏è Vector store ƒë√£ b·ªã x√≥a. B·∫°n c·∫ßn t·∫°o l·∫°i index tr∆∞·ªõc khi th·ª±c hi·ªán truy v·∫•n."
        )

    def _select_prompt_template(self, query: str, docs: List[Any]) -> str:
        """Ch·ªçn template prompt ph√π h·ª£p d·ª±a tr√™n n·ªôi dung query v√† t√†i li·ªáu

        Args:
            query: C√¢u truy v·∫•n
            docs: Danh s√°ch t√†i li·ªáu li√™n quan

        Returns:
            Template prompt ph√π h·ª£p
        """
        # Ph√°t hi·ªán y√™u c·∫ßu t·∫°o SQL
        sql_generation_keywords = [
            "vi·∫øt sql",
            "t·∫°o sql",
            "generate sql",
            "create query",
            "write a query",
            "vi·∫øt truy v·∫•n",
        ]
        if any(kw in query.lower() for kw in sql_generation_keywords):
            return get_sql_generation_prompt

        # Ph√°t hi·ªán ph√¢n t√≠ch schema
        schema_keywords = [
            "ph√¢n t√≠ch schema",
            "analyze schema",
            "ƒë√°nh gi√° thi·∫øt k·∫ø",
            "evaluate design",
            "database design",
        ]
        if any(kw in query.lower() for kw in schema_keywords):
            return get_schema_analysis_prompt

        # Ph√°t hi·ªán t√†i li·ªáu SQL trong context
        has_sql_docs = False
        for doc in docs:
            if "sql_document_type" in doc.metadata or "sql_type" in doc.metadata:
                has_sql_docs = True
                break

        # S·ª≠ d·ª•ng prompt CSDL n·∫øu c√≥ t√†i li·ªáu SQL
        if has_sql_docs:
            return get_database_query_prompt

        # M·∫∑c ƒë·ªãnh d√πng prompt c∆° s·ªü d·ªØ li·ªáu v√¨ ƒë√¢y l√† h·ªá th·ªëng chuy√™n v·ªÅ CSDL
        return get_database_query_prompt

    @measure_time
    def query(self, query_text: str) -> Dict[str, Any]:
        """Truy v·∫•n RAG Pipeline

        Args:
            query_text: C√¢u truy v·∫•n ng∆∞·ªùi d√πng

        Returns:
            Dict ch·ª©a c√¢u tr·∫£ l·ªùi v√† c√°c th√¥ng tin b·ªï sung
        """
        # Kh·ªüi t·∫°o k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh
        result = {
            "text": "",
            "sources": [],
            "prompt": "",
            "query": query_text,
            "model": "",
            "temperature": 0.0,
            "total_sources": 0,
            "retrieval_time": 0.0,
            "llm_time": 0.0,
        }

        # Ki·ªÉm tra xem collection c√≥ t·ªìn t·∫°i kh√¥ng
        if not self.vector_store_manager.client.collection_exists(
            self.vector_store_manager.collection_name
        ):
            print(
                f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} kh√¥ng t·ªìn t·∫°i. Vui l√≤ng t·∫°o index tr∆∞·ªõc."
            )
            result["text"] = (
                "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng t·∫°o index tr∆∞·ªõc b·∫±ng l·ªánh: python -m src.main index --data-dir ./data"
            )
            return result

        # ƒê·∫£m b·∫£o vectorstore ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        if self.vectorstore is None:
            self._reinitialize_vectorstore()
            # N·∫øu v·∫´n kh√¥ng kh·ªüi t·∫°o ƒë∆∞·ª£c
            if self.vectorstore is None:
                result["text"] = (
                    "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn vector store. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh v√† k·∫øt n·ªëi."
                )
                return result

        # Ki·ªÉm tra xem collection c√≥ ch·ª©a d·ªØ li·ªáu kh√¥ng
        try:
            collection_info = self.vector_store_manager.client.get_collection(
                self.vector_store_manager.collection_name
            )
            vector_count = collection_info.vectors_count
            if vector_count == 0:
                print(
                    f"‚ö†Ô∏è Collection {self.vector_store_manager.collection_name} r·ªóng (0 vectors)"
                )
                result["text"] = (
                    "Kh√¥ng th·ªÉ truy v·∫•n v√¨ ch∆∞a c√≥ d·ªØ li·ªáu trong vector store. Vui l√≤ng upload v√† index t√†i li·ªáu tr∆∞·ªõc."
                )
                return result
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ki·ªÉm tra d·ªØ li·ªáu trong collection: {str(e)}")
            result["text"] = f"L·ªói khi ki·ªÉm tra d·ªØ li·ªáu: {str(e)}"
            return result

        # 1. L·∫•y t√†i li·ªáu li√™n quan
        retrieval_start = time.time()

        # S·ª≠ d·ª•ng RAG Fusion n·∫øu ƒë∆∞·ª£c b·∫≠t, n·∫øu kh√¥ng s·ª≠ d·ª•ng retriever th√¥ng th∆∞·ªùng
        if self.fusion and QUERY_EXPANSION_ENABLED:
            # S·ª≠ d·ª•ng fusion.retrieve() trong FAST_MODE ƒë·ªÉ tr√°nh rerank hai l·∫ßn
            # fusion.retrieve s·∫Ω t·ª± ƒë·ªông s·ª≠ d·ª•ng reranker n·∫øu RERANK_RETRIEVAL_RESULTS=True
            relevant_docs = self.fusion.retrieve(query_text)
        else:
            relevant_docs = self.retriever.retrieve(query_text)

        retrieval_end = time.time()
        result["retrieval_time"] = retrieval_end - retrieval_start

        # 2. T·∫°o c√¢u tr·∫£ l·ªùi v·ªõi LLM
        llm_start = time.time()

        # Ch·ªçn prompt template ph√π h·ª£p
        prompt_template = self._select_prompt_template(query_text, relevant_docs)

        # T·∫°o response v·ªõi LLM
        response_dict = self.llm.generate_response(
            query_text, relevant_docs, prompt_template=prompt_template
        )

        llm_end = time.time()
        result["llm_time"] = llm_end - llm_start

        # 3. G·ªôp k·∫øt qu·∫£ t·ª´ LLM v√†o k·∫øt qu·∫£ cu·ªëi c√πng
        result.update(response_dict)

        # 4. B·ªï sung th√¥ng tin th√™m
        result["query"] = query_text
        result["total_tokens"] = len(query_text.split()) + len(result["text"].split())

        return result
